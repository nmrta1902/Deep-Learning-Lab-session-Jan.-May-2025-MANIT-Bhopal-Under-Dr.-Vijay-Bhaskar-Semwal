{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TMEA7dTA2U4",
        "outputId": "8a363132-f702-4730-b370-65c8e67e7a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incomplete word: MACHIN\n",
            "RNN prediction: E\n",
            "Bidirectional RNN prediction: E\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Bidirectional, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define a richer dataset\n",
        "words = [\"MACHINE\", \"MACHO\", \"MACRON\", \"MAGNET\", \"MATCHES\", \"MATCHER\", \"MATCHING\", \"MATCH\", \"MACHINERY\"]\n",
        "\n",
        "# Vocabulary\n",
        "alphabet = sorted(set(''.join(words)))\n",
        "char_to_int = {c: i+1 for i, c in enumerate(alphabet)}  # start from 1\n",
        "int_to_char = {i: c for c, i in char_to_int.items()}\n",
        "vocab_size = len(char_to_int) + 1  # +1 for padding\n",
        "\n",
        "# Create sequences to predict the last character\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for word in words:\n",
        "    input_seq = list(word[:-1])  # remove last char\n",
        "    label = word[-1]             # target is the last char\n",
        "    encoded_seq = [char_to_int[c] for c in input_seq]\n",
        "    sequences.append(encoded_seq)\n",
        "    labels.append(char_to_int[label])\n",
        "\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "y = to_categorical(labels, num_classes=vocab_size)\n",
        "\n",
        "# Build simple RNN\n",
        "def build_rnn():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=10),\n",
        "        SimpleRNN(64),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build Bidirectional RNN\n",
        "def build_birnn():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=10),\n",
        "        Bidirectional(SimpleRNN(64)),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train models\n",
        "rnn_model = build_rnn()\n",
        "rnn_model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "birnn_model = build_birnn()\n",
        "birnn_model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# Prediction\n",
        "def predict_last_letter(model, partial_word):\n",
        "    encoded = [char_to_int[c] for c in partial_word]\n",
        "    padded = pad_sequences([encoded], maxlen=max_len, padding='pre')\n",
        "    pred = model.predict(padded, verbose=0)\n",
        "    return int_to_char[np.argmax(pred)]\n",
        "\n",
        "# Example: \"MACHIN\" â†’ Predict \"E\"\n",
        "incomplete = list(\"MACHIN\")\n",
        "rnn_pred = predict_last_letter(rnn_model, incomplete)\n",
        "birnn_pred = predict_last_letter(birnn_model, incomplete)\n",
        "\n",
        "print(f\"Incomplete word: {''.join(incomplete)}\")\n",
        "print(f\"RNN prediction: {rnn_pred}\")\n",
        "print(f\"Bidirectional RNN prediction: {birnn_pred}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "# 1. Text Preprocessing\n",
        "sentences = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"The dog sat on the rug\",\n",
        "    \"The bird flew in the sky\",\n",
        "    \"The cat jumped over the fence\"\n",
        "]\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create sequences: e.g. \"The cat sat\" -> predict \"on\"\n",
        "input_sequences = []\n",
        "labels = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    tokens = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(tokens)):\n",
        "        input_sequences.append(tokens[:i])\n",
        "        labels.append(tokens[i])\n",
        "\n",
        "# Pad sequences\n",
        "max_len = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
        "\n",
        "# Convert labels to categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "labels = to_categorical(labels, num_classes=vocab_size)\n",
        "\n",
        "# 2. Model Building\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len),\n",
        "    SimpleRNN(64),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train the Model\n",
        "model.fit(input_sequences, labels, epochs=500, verbose=0)\n",
        "\n",
        "# 4. Prediction\n",
        "def predict_next_word(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "    padded = pad_sequences([sequence], maxlen=max_len, padding='pre')\n",
        "    pred = model.predict(padded, verbose=0)\n",
        "    next_word_id = np.argmax(pred)\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "        if idx == next_word_id:\n",
        "            return word\n",
        "    return \"?\"\n",
        "\n",
        "# Test\n",
        "test_input = \"The cat sat on\"\n",
        "predicted_word = predict_next_word(test_input)\n",
        "\n",
        "print(f\"Input Sentence: '{test_input}'\")\n",
        "print(f\"Predicted Next Word: '{predicted_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9UK4FT2Bn6a",
        "outputId": "457f073e-3f94-4753-803b-9615f0280366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: 'The cat sat on'\n",
            "Predicted Next Word: 'the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define full note vocabulary (include variations)\n",
        "all_notes = ['Sa', 'Re', 'Reb', 'Ga', 'Gab', 'Ma', 'Ma#', 'Pa', 'Dha', 'Dhab', 'Ni', 'Sha']\n",
        "note_to_int = {note: i for i, note in enumerate(all_notes)}\n",
        "int_to_note = {i: note for note, i in note_to_int.items()}\n",
        "vocab_size = len(all_notes)\n",
        "\n",
        "# Define ragas with simplified sequences\n",
        "ragas = {\n",
        "    \"Bhairav\": ['Sa', 'Reb', 'Ga', 'Ma', 'Pa', 'Dhab', 'Ni', 'Sha'],\n",
        "    \"Bhopali\": ['Sa', 'Re', 'Ga', 'Pa', 'Dha', 'Sha'],\n",
        "    \"Bageshree\": ['Sa', 'Gab', 'Ma', 'Dha', 'Ni', 'Sha'],\n",
        "    \"Yaman\": ['Sa', 'Re', 'Ga', 'Ma#', 'Pa', 'Dha', 'Ni', 'Sha'],\n",
        "    \"Desh\": ['Sa', 'Re', 'Ma', 'Pa', 'Ni', 'Sha']\n",
        "}\n",
        "\n",
        "# Function to generate sequences\n",
        "def generate_sequences(raga_notes, n_sequences=500):\n",
        "    sequences = []\n",
        "    for _ in range(n_sequences):\n",
        "        start = random.randint(0, len(raga_notes) - 4)\n",
        "        seq = raga_notes[start:start+4]\n",
        "        sequences.append(seq)\n",
        "    return sequences\n",
        "\n",
        "# Function to train and generate from a specific raga\n",
        "def train_and_generate_raga(raga_name, seed_notes, sequence_length=10):\n",
        "    print(f\"\\nTraining on Raga: {raga_name}\")\n",
        "    raga_notes = ragas[raga_name]\n",
        "    sequences = generate_sequences(raga_notes)\n",
        "\n",
        "    # Preprocess\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            input_seq = [note_to_int[n] for n in seq[:i]]\n",
        "            label = note_to_int[seq[i]]\n",
        "            X.append(input_seq)\n",
        "            y.append(label)\n",
        "\n",
        "    max_len = max(len(seq) for seq in X)\n",
        "    X = pad_sequences(X, maxlen=max_len, padding='pre')\n",
        "    y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "    # Build RNN\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len),\n",
        "        SimpleRNN(64),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X, y, epochs=300, verbose=0)\n",
        "\n",
        "    # Generate\n",
        "    generated = seed_notes.copy()\n",
        "    for _ in range(sequence_length):\n",
        "        encoded = [note_to_int[n] for n in generated[-max_len:]]\n",
        "        padded = pad_sequences([encoded], maxlen=max_len, padding='pre')\n",
        "        pred = model.predict(padded, verbose=0)\n",
        "        next_index = np.argmax(pred)\n",
        "        next_note = int_to_note[next_index]\n",
        "        generated.append(next_note)\n",
        "\n",
        "    print(\"Seed:\", seed_notes)\n",
        "    print(\"Generated Sequence:\", generated)\n",
        "\n",
        "# Call for multiple ragas\n",
        "train_and_generate_raga(\"Bhairav\", ['Sa', 'Reb'])\n",
        "train_and_generate_raga(\"Bhopali\", ['Sa', 'Re'])\n",
        "train_and_generate_raga(\"Bageshree\", ['Sa', 'Gab'])\n",
        "train_and_generate_raga(\"Yaman\", ['Sa', 'Re'])\n",
        "train_and_generate_raga(\"Desh\", ['Sa', 'Re'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvLUfLQ0D0E_",
        "outputId": "4e6c0aa1-1e4a-4392-afa4-a9376a914a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on Raga: Bhairav\n",
            "Seed: ['Sa', 'Reb']\n",
            "Generated Sequence: ['Sa', 'Reb', 'Ga', 'Ma', 'Pa', 'Dhab', 'Ni', 'Sha', 'Sha', 'Sha', 'Sha', 'Sha']\n",
            "\n",
            "Training on Raga: Bhopali\n",
            "Seed: ['Sa', 'Re']\n",
            "Generated Sequence: ['Sa', 'Re', 'Ga', 'Pa', 'Dha', 'Sha', 'Sha', 'Dha', 'Dha', 'Sha', 'Dha', 'Dha']\n",
            "\n",
            "Training on Raga: Bageshree\n",
            "Seed: ['Sa', 'Gab']\n",
            "Generated Sequence: ['Sa', 'Gab', 'Ma', 'Dha', 'Ni', 'Sha', 'Sha', 'Ni', 'Sha', 'Sha', 'Ni', 'Sha']\n",
            "\n",
            "Training on Raga: Yaman\n",
            "Seed: ['Sa', 'Re']\n",
            "Generated Sequence: ['Sa', 'Re', 'Ga', 'Ma#', 'Pa', 'Dha', 'Ni', 'Sha', 'Dha', 'Ni', 'Pa', 'Dha']\n",
            "\n",
            "Training on Raga: Desh\n",
            "Seed: ['Sa', 'Re']\n",
            "Generated Sequence: ['Sa', 'Re', 'Ma', 'Pa', 'Ni', 'Sha', 'Sha', 'Ni', 'Sha', 'Ni', 'Sha', 'Ni']\n"
          ]
        }
      ]
    }
  ]
}